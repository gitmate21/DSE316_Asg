{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Q4\n",
        "Build a classifier for Street View House Numbers (SVHN) (Dataset) using pretrained model weights from PyTorch. Try multiple\n",
        "models like LeNet-5, AlexNet, VGG, or ResNet(18, 50, 101). Compare performance comment why a particular model is well suited\n",
        "for SVHN dataset. (You can use a subset of dataset (25%) in case you do not have enough compute.)"
      ],
      "metadata": {
        "id": "BPdJQIOYWTVR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uYOPQ22HWPxT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import os\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random seed for reproducibility\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Loadind and preprocessing SVHN dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # Resize images to match the input size expected by the models\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize pixel values to [-1, 1]\n",
        "])\n",
        "\n",
        "train_dataset = datasets.SVHN(root='./data', split='train', transform=transform, download=True)\n",
        "test_dataset = datasets.SVHN(root='./data', split='test', transform=transform, download=True)\n",
        "\n",
        "\n",
        "train_subset = torch.utils.data.Subset(train_dataset, np.random.choice(len(train_dataset), int(0.25 * len(train_dataset)), replace=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW-p_F0VWkrw",
        "outputId": "5e08c057-5735-4503-8ffa-d5e5de9102dc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./data/train_32x32.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182040794/182040794 [00:21<00:00, 8301012.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to ./data/test_32x32.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64275384/64275384 [00:15<00:00, 4225538.68it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "download_path = './pretrained_weights/'\n",
        "\n",
        "# Creating directory if it doesn't exist\n",
        "os.makedirs(download_path, exist_ok=True)\n",
        "\n",
        "# Defining VGG16 with pretrained weights\n",
        "vgg = models.vgg16(pretrained=True)\n",
        "# Saving the pretrained weights\n",
        "torch.save(vgg.state_dict(), os.path.join(download_path, 'vgg_pretrained_weights.pth'))\n",
        "\n",
        "# Defining ResNet-18 with pretrained weights\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "# Saving the pretrained weights\n",
        "torch.save(resnet18.state_dict(), os.path.join(download_path, 'resnet18_pretrained_weights.pth'))\n",
        "\n",
        "# Defining ResNet-50 with pretrained weights\n",
        "resnet50 = models.resnet50(pretrained=True)\n",
        "# Saving the pretrained weights\n",
        "torch.save(resnet50.state_dict(), os.path.join(download_path, 'resnet50_pretrained_weights.pth'))\n",
        "\n",
        "# Defining ResNet-101 with pretrained weights\n",
        "resnet101 = models.resnet101(pretrained=True)\n",
        "# Saving the pretrained weights\n",
        "torch.save(resnet101.state_dict(), os.path.join(download_path, 'resnet101_pretrained_weights.pth'))\n"
      ],
      "metadata": {
        "id": "Zr908DX_W3f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23192bdf-3974-48e4-c40b-37766b284457"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:03<00:00, 151MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 151MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 128MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100%|██████████| 171M/171M [00:03<00:00, 52.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading pretrained weights\n",
        "\n",
        "vgg_weights = torch.load('./pretrained_weights/vgg_pretrained_weights.pth')\n",
        "resnet18_weights = torch.load('./pretrained_weights/resnet18_pretrained_weights.pth')\n",
        "resnet50_weights = torch.load('./pretrained_weights/resnet50_pretrained_weights.pth')\n",
        "resnet101_weights = torch.load('./pretrained_weights/resnet101_pretrained_weights.pth')\n"
      ],
      "metadata": {
        "id": "tsONpR-uY_HM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "lTymQiBbaEmI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_subset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "M8sh5Z2RaRfp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, num_epochs=5, device=torch.device(\"cuda\")):\n",
        "    model.to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_correct += (predicted.cpu() == labels.cpu()).sum().item()  # Move predicted and labels back to CPU for accuracy calculation\n",
        "            total_samples += labels.size(0)\n",
        "    accuracy = total_correct / total_samples\n",
        "    print(f\"Accuracy: {accuracy}\\n\")\n",
        "\n",
        "# Training and evaluating models\n",
        "models = [vgg, resnet18, resnet50, resnet101]\n",
        "model_names = ['VGG-16', 'ResNet-18', 'ResNet-50', 'ResNet-101']\n",
        "\n",
        "for model, model_name in zip(models, model_names):\n",
        "    print(f'Training and evaluating {model_name}...\\n')\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "    train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, device=torch.device(\"cuda\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRUoYtwdvZn_",
        "outputId": "46fb5a12-7e70-4384-e29a-65d47625ae24"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating VGG-16...\n",
            "\n",
            "Epoch 1/5, Loss: 2.288294100595268\n",
            "Epoch 2/5, Loss: 1.058486030284536\n",
            "Epoch 3/5, Loss: 0.49857990267177077\n",
            "Epoch 4/5, Loss: 0.35887506611982706\n",
            "Epoch 5/5, Loss: 0.2855098379795352\n",
            "Accuracy: 0.9094960049170252\n",
            "\n",
            "Training and evaluating ResNet-18...\n",
            "\n",
            "Epoch 1/5, Loss: 2.0546019673347473\n",
            "Epoch 2/5, Loss: 0.7374378602679182\n",
            "Epoch 3/5, Loss: 0.5432222432064262\n",
            "Epoch 4/5, Loss: 0.3694945172981103\n",
            "Epoch 5/5, Loss: 0.29688645213946235\n",
            "Accuracy: 0.8845267363245236\n",
            "\n",
            "Training and evaluating ResNet-50...\n",
            "\n",
            "Epoch 1/5, Loss: 2.3068630649653046\n",
            "Epoch 2/5, Loss: 1.5649826250425198\n",
            "Epoch 3/5, Loss: 1.01850483984482\n",
            "Epoch 4/5, Loss: 0.8195795713816786\n",
            "Epoch 5/5, Loss: 0.7497649172041889\n",
            "Accuracy: 0.7956745543945912\n",
            "\n",
            "Training and evaluating ResNet-101...\n",
            "\n",
            "Epoch 1/5, Loss: 2.6094645938806833\n",
            "Epoch 2/5, Loss: 2.429790206902534\n",
            "Epoch 3/5, Loss: 2.3804311278805086\n",
            "Epoch 4/5, Loss: 2.3331697888490632\n",
            "Epoch 5/5, Loss: 2.094680352078082\n",
            "Accuracy: 0.4108020897357099\n",
            "\n"
          ]
        }
      ]
    }
  ]
}